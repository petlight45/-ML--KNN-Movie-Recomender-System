{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing the needed libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, seaborn as sns, matplotlib.pyplot as plt,numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler,QuantileTransformer\n",
    "from rapidfuzz import process,fuzz\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining the movie querier function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "import numpy as np\n",
    "\n",
    "def get_name_movie(queried_movie_name, train_movies_1d, movie_type):\n",
    "    query_method = None\n",
    "    \n",
    "    #This function compiles the queried movie data into the format needed(TV-SHOW ONLY)\n",
    "    def compile_meta_show(imdbID=np.nan, title=np.nan, url=np.nan, imdbRating=np.nan, imdbVotes=np.nan, duration=np.nan,\n",
    "                          year=np.nan, noOfAwards=np.nan, noOfNominations=np.nan, Action=0, Adult=0, Adventure=0,\n",
    "                          Animation=0, Biography=0, Comedy=0, Crime=0, Documentary=0, Drama=0, Family=0, Fantasy=0,\n",
    "                          FilmNoir=0, GameShow=0, History=0, Horror=0, Music=0, Musical=0, Mystery=0, News=0,\n",
    "                          RealityTV=0, Romance=0, SciFi=0, Short=0, Sport=0, TalkShow=0, Thriller=0, War=0, Western=0,\n",
    "                          directors=np.nan, writers=np.nan, actors=np.nan, country=np.nan, language=np.nan, Type=np.nan,\n",
    "                          Plot=np.nan, Rated=np.nan, Genre=np.nan, totalSeasons=np.nan, specialNominations=np.nan):\n",
    "        url = f'http://www.imdb.com/title/{imdbID}/'\n",
    "        return [imdbID, title, url, imdbRating, imdbVotes, duration, year, specialNominations, noOfAwards,\n",
    "                noOfNominations, Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama,\n",
    "                Family, Fantasy, FilmNoir, GameShow, History, Horror, Music, Musical, Mystery, News, RealityTV, Romance,\n",
    "                SciFi, Short, Sport, TalkShow, Thriller, War, Western, directors, writers, actors, country, language,\n",
    "                Type, Plot, Rated, Genre, totalSeasons]\n",
    "    \n",
    "    #This function compiles the queried movie data into the format needed(MOVIES ONLY)\n",
    "    def compile_meta(imdbID=np.nan, title=np.nan, url=np.nan, imdbRating=np.nan,\n",
    "                     rottenTomatoRating=np.nan, metacriticRating=np.nan,\n",
    "                     imdbVotes=np.nan, duration=np.nan, year=np.nan,\n",
    "                     oscarNominations=np.nan, noOfAwards=np.nan, noOfNominations=np.nan, Action=0, Adult=0, Adventure=0,\n",
    "                     Animation=0, Biography=0, Comedy=0, Crime=0, Documentary=0, Drama=0, Family=0, Fantasy=0,\n",
    "                     FilmNoir=0, GameShow=0, History=0, Horror=0, Music=0, Musical=0, Mystery=0, News=0,\n",
    "                     RealityTV=0, Romance=0, SciFi=0, Short=0, Sport=0, TalkShow=0, Thriller=0, War=0,\n",
    "                     Western=0, directors=np.nan, writers=np.nan, actors=np.nan, production=np.nan,\n",
    "                     country=np.nan, language=np.nan, Type=np.nan, Plot=np.nan, BoxOffice=np.nan, Rated=np.nan,\n",
    "                     Genre=np.nan):\n",
    "        url = f'http://www.imdb.com/title/{imdbID}/'\n",
    "        return [imdbID, title, url, imdbRating, rottenTomatoRating, metacriticRating,\n",
    "                imdbVotes, duration, year, oscarNominations, noOfAwards, noOfNominations,\n",
    "                Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary,\n",
    "                Drama, Family, Fantasy, FilmNoir, GameShow, History, Horror, Music, Musical,\n",
    "                Mystery, News, RealityTV, Romance, SciFi, Short, Sport, TalkShow, Thriller,\n",
    "                War, Western, directors, writers, actors, production, country, language,\n",
    "                Type, Plot, BoxOffice, Rated, Genre\n",
    "                ]\n",
    "    #This function gets the meta information of the queried movie by using its IMDB ID\n",
    "    def get_meta(movie_id, type_):\n",
    "        url = \"https://movie-database-imdb-alternative.p.rapidapi.com/\"\n",
    "        headers = {\n",
    "            'x-rapidapi-host': \"movie-database-imdb-alternative.p.rapidapi.com\",\n",
    "            'x-rapidapi-key': \"ce15ebaf8dmshfb3801d1cfa22dcp1f4c05jsn1dad2b361974\"\n",
    "        }\n",
    "        querystring = {\"i\": f\"{movie_id}\", \"r\": \"json\", 'type': type_}\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "        return (response.json())\n",
    "\n",
    "    #This function gets the IMDB ID of a queried movie name\n",
    "    def get_id(m_name, type_):\n",
    "        url = \"https://movie-database-imdb-alternative.p.rapidapi.com/\"\n",
    "        headers = {\n",
    "            'x-rapidapi-host': \"movie-database-imdb-alternative.p.rapidapi.com\",\n",
    "            'x-rapidapi-key': \"ce15ebaf8dmshfb3801d1cfa22dcp1f4c05jsn1dad2b361974\"\n",
    "        }\n",
    "        querystring = {\"page\": \"1\", \"r\": \"json\", \"s\": f\"{m_name}\", 'type': type_}\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "        return (response.json()['Search'][0]['imdbID'])\n",
    "\n",
    "    try:\n",
    "        m_id = get_id(queried_movie_name, movie_type)\n",
    "        query_method = 'API Search'\n",
    "    except KeyError as err:\n",
    "        m_id = \\\n",
    "            process.extractOne(queried_movie_name.lower(), train_movies_1d, scorer=fuzz.token_set_ratio)[0].split(\":\")[\n",
    "                -1]\n",
    "        query_method = 'DATA Search'\n",
    "    except ConnectionError as err:\n",
    "        return (None, 'Connection Error')\n",
    "    except Exception as err:\n",
    "        return (None, err)\n",
    "    try:\n",
    "        movie_meta = get_meta(m_id, movie_type)\n",
    "        if movie_type != \"series\":\n",
    "            log_obj = dict()\n",
    "            log_obj['imdbID'] = movie_meta['imdbID']\n",
    "            log_obj['title'] = movie_meta['Title'].replace(',', \"-\")\n",
    "            dict_ratings = {\n",
    "                'Internet Movie Database': {'name': 'imdbRating', 'pattern': r'(.+?)/'},\n",
    "                'Rotten Tomatoes': {'name': 'rottenTomatoRating', 'pattern': r'(.+?)%'},\n",
    "                'Metacritic': {'name': 'metacriticRating', 'pattern': r'(.+?)/'}\n",
    "            }\n",
    "            for i, j in [(i['Source'], i['Value']) for i in movie_meta['Ratings']]:\n",
    "                log_obj[dict_ratings[i]['name']] = float(re.findall(dict_ratings[i]['pattern'], j)[0])\n",
    "            try:\n",
    "                log_obj['imdbVotes'] = int(movie_meta['imdbVotes'].replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                log_obj['duration'] = int(re.findall(r'(\\d+)', movie_meta['Runtime'])[0]) * 60\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['year'] = movie_meta['Year']\n",
    "            nomination_text = movie_meta['Awards']\n",
    "            if 'Oscar' in nomination_text:\n",
    "                log_obj['oscarNominations'] = int(re.findall(r'(\\d+) Oscar', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'nominations' in nomination_text:\n",
    "                log_obj['noOfNominations'] = int(\n",
    "                    re.findall(r'(\\d+) nominations', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'wins' in nomination_text:\n",
    "                log_obj['noOfAwards'] = int(re.findall(r'(\\d+) wins', nomination_text, re.IGNORECASE)[0])\n",
    "            for i in movie_meta['Genre'].split(','):\n",
    "                log_obj[i.replace(' ', '').replace('-', '')] = 1\n",
    "            log_obj['directors'] = movie_meta['Director'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['writers'] = movie_meta['Writer'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['actors'] = movie_meta['Actors'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            try:\n",
    "                log_obj['production'] = movie_meta['Production'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['country'] = movie_meta['Country'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['language'] = movie_meta['Language'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Plot'] = movie_meta['Plot'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Type'] = movie_meta['Type'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Rated'] = movie_meta['Rated'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            try:\n",
    "                log_obj['BoxOffice'] = movie_meta['BoxOffice'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['Genre'] = movie_meta['Genre'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            if 'N/A' in log_obj.keys():\n",
    "                del log_obj['N/A']\n",
    "            return (compile_meta(**log_obj), query_method, None)\n",
    "        else:\n",
    "            log_obj = dict()\n",
    "            log_obj['imdbID'] = movie_meta['imdbID']\n",
    "            log_obj['title'] = movie_meta['Title'].replace(',', \"-\")\n",
    "            dict_ratings = {\n",
    "                'Internet Movie Database': {'name': 'imdbRating', 'pattern': r'(.+?)/'}\n",
    "            }\n",
    "            for i, j in [(i['Source'], i['Value']) for i in movie_meta['Ratings']]:\n",
    "                try:\n",
    "                    log_obj[dict_ratings[i]['name']] = float(re.findall(dict_ratings[i]['pattern'], j)[0])\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                log_obj['imdbVotes'] = int(movie_meta['imdbVotes'].replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                log_obj['duration'] = int(re.findall(r'(\\d+)', movie_meta['Runtime'])[0]) * 60\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['year'] = movie_meta['Year']\n",
    "            nomination_text = movie_meta['Awards']\n",
    "            log_obj['specialNominations'] = 'None'\n",
    "            log_obj['noOfNominations'] = 0\n",
    "            log_obj['noOfAwards'] = 0\n",
    "            if 'nominated for' in nomination_text.lower():\n",
    "                for (value, nomination) in re.findall(r'(\\d+?)\\s([a-zA-Z\\s]+)', nomination_text, re.IGNORECASE):\n",
    "                    if not ('nomination' in nomination or 'win' in nomination):\n",
    "                        log_obj['specialNominations'] += f'{value}:{nomination};'\n",
    "            if 'nomination' in nomination_text:\n",
    "                log_obj['noOfNominations'] = int(re.findall(r'(\\d+) nomination', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'win' in nomination_text:\n",
    "                log_obj['noOfAwards'] = int(re.findall(r'(\\d+) win', nomination_text, re.IGNORECASE)[0])\n",
    "            for i in movie_meta['Genre'].split(','):\n",
    "                log_obj[i.replace(' ', '').replace('-', '')] = 1\n",
    "            log_obj['directors'] = movie_meta['Director'].replace(\",\", '-')\n",
    "            log_obj['writers'] = movie_meta['Writer'].replace(\",\", '-')\n",
    "            log_obj['actors'] = movie_meta['Actors'].replace(\",\", '-')\n",
    "            log_obj['country'] = movie_meta['Country'].replace(\",\", '-')\n",
    "            log_obj['language'] = movie_meta['Language'].replace(\",\", '-')\n",
    "            log_obj['Plot'] = movie_meta['Plot'].replace(\",\", '-')\n",
    "            log_obj['Type'] = movie_meta['Type'].replace(\",\", '-')\n",
    "            log_obj['Rated'] = movie_meta['Rated'].replace(\",\", '-')\n",
    "            log_obj['Genre'] = movie_meta['Genre'].replace(\",\", '-')\n",
    "            try:\n",
    "                log_obj['totalSeasons'] = int(movie_meta['totalSeasons'])\n",
    "            except:\n",
    "                pass\n",
    "            if 'N/A' in log_obj.keys():\n",
    "                del log_obj['N/A']\n",
    "            return (compile_meta_show(**log_obj), query_method, None)\n",
    "    except ConnectionError as err:\n",
    "        return (None, 'Connection Error')\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "        return (None, 'Unknown error encountered')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining the predicting algorithm</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz,process\n",
    "import math,re,numpy as np,pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def euclidean_distance(one_d_arr_1,one_d_arr_2):\n",
    "\tif (len(one_d_arr_2) != len(one_d_arr_2)):\n",
    "\t\traise Exception('Eucidean Distance Error; the two 1D arrays have mismatched lengths')\n",
    "\treturn np.linalg.norm(one_d_arr_2-one_d_arr_1)\n",
    "\n",
    "\n",
    "def extract_values(one_d_arr, indices):\n",
    "\treturn one_d_arr[indices]\n",
    "\n",
    "def sort_template_by_rank(distance_template):\n",
    "\treturn sorted(distance_template, key=lambda r:r[0])\n",
    "\n",
    "def compute_distances(query_data_1d, train_data_2d, distance_template):\n",
    "\tsorted_distance_template = sort_template_by_rank(distance_template)\n",
    "\tdistances_computed = list()\n",
    "\tpattern_d_ratio = re.compile('d(\\d+)')\n",
    "\tfor id_, data in enumerate(train_data_2d):\n",
    "\t\tdistance_values =list()\n",
    "\t\tfor *_, indices, method, d_ratio,multiplier in sorted_distance_template:\n",
    "\t\t\tvalues_query = extract_values(query_data_1d, indices)\n",
    "\t\t\tvalues_train = extract_values(data, indices)\n",
    "\t\t\tdistance = euclidean_distance(values_query.astype(np.float64),values_train.astype(np.float64))\n",
    "\t\t\tif pattern_d_ratio.findall(d_ratio)[0] == \"1\":\n",
    "\t\t\t\tdistance = distance\n",
    "\t\t\telse:\n",
    "\t\t\t\tdistance = round(distance / int(pattern_d_ratio.findall(d_ratio)[0]))\n",
    "\t\t\tdistance_values.append((distance,multiplier))\n",
    "\t\tdistances_computed.append((id_, distance_values))\n",
    "\treturn distances_computed\n",
    "\n",
    "def sort_distances_computed(distances_computed):\n",
    "\tdef sorter(x):\n",
    "\t\tsorting_list = list()\n",
    "\t\tfor v,m in x[1]:\n",
    "\t\t\tsorting_list.append(v*m)\n",
    "\t\treturn sorting_list\n",
    "\treturn sorted(distances_computed, key=sorter)\n",
    "\n",
    "\n",
    "\n",
    "def extract_n_neighbours_data(extracting_indices_1d, train_data_2d,k):\n",
    "\tif k > len(extracting_indices_1d):\n",
    "\t\traise Exception('K Error; k > avaailable train data')\n",
    "\tif k == -1:\n",
    "\t\treturn train_data_2d[extracting_indices_1d]\n",
    "\telse:\n",
    "\t\treturn train_data_2d[extracting_indices_1d[:k]]\n",
    "\n",
    "def extract_recommended_distances(sorted_distances_computed,k):\n",
    "\tif k > len(sorted_distances_computed):\n",
    "\t\traise Exception('K Error; k > avaailable train data')\n",
    "\tif k == -1:\n",
    "\t\treturn list(j for *_,j in sorted_distances_computed)\n",
    "\telse:\n",
    "\t\treturn list(j for *_,j in sorted_distances_computed[:k])\n",
    "\n",
    "def extract_recommeded_indices(sorted_distances_computed, k):\n",
    "\n",
    "\tif k > len(sorted_distances_computed):\n",
    "\t\traise Exception('K Error; k > available train data')\n",
    "\tif k == -1:\n",
    "\t\treturn list(i for i,*_ in sorted_distances_computed)\n",
    "\telse:\n",
    "\t\treturn list(i for i,*_ in sorted_distances_computed[:k])\n",
    "\n",
    "\n",
    "def compile_final_output(label_data, recommended_data_2d,recommeded_distances,recommeded_names):\n",
    "\tfinal_label = [*label_data,'Movie Title']\n",
    "\tfinal_data = np.hstack((recommended_data_2d,recommeded_names[:,np.newaxis]))\n",
    "\treturn pd.DataFrame(data=final_data, columns=final_label)\n",
    "\n",
    "\n",
    "def model_knn(k_neighbours, train_data_2d, query_data_1d,train_data_movie_titles_1d,distance_template, label_data=None):\n",
    "\tdistances_computed = compute_distances(query_data_1d,train_data_2d,distance_template)\n",
    "\tsorted_distances_computed = sort_distances_computed(distances_computed)\n",
    "\textracting_indices = list(i for i,*_ in sorted_distances_computed)\n",
    "\trecommended_data_2d = extract_n_neighbours_data(extracting_indices, train_data_2d, k_neighbours)\n",
    "\trecommeded_distances = extract_recommended_distances(sorted_distances_computed, k_neighbours)\n",
    "\trecommeded_indices = extract_recommeded_indices(sorted_distances_computed,k_neighbours)\n",
    "\trecommeded_names = train_data_movie_titles_1d[recommeded_indices]\n",
    "\treturn compile_final_output(label_data,recommended_data_2d,recommeded_distances,recommeded_names),recommeded_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading The Movies Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollywood_data = pd.read_csv(r\"data\\hollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "bollywood_data = pd.read_csv(r\"data\\bollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "british_data = pd.read_csv(r\"data\\british.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "chinese_data = pd.read_csv(r\"data\\chinese.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "korean_data = pd.read_csv(r\"data\\korean.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "nollywood_data = pd.read_csv(r\"data\\nollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "thai_data = pd.read_csv(r\"data\\thai.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "am_shows_data = pd.read_csv(r\"data\\america_tv_show.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "k_drama_data = pd.read_csv(r\"data\\korean_drama.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Cleaning and Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining parsing and filtering functions for year of production of the movies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function filters out movies that are produced before 2005(TV-SHOW Only)\n",
    "def parse_year_show(x):\n",
    "    try:\n",
    "        return int(x.split('–')[0]) >= 2005\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "#This function filters out movies that are produced before a specified year(defaults to 1990)(MOVIES Only)\n",
    "def filter_year(year, limit=1990):\n",
    "    try:\n",
    "        return int(year) >= limit\n",
    "    except:\n",
    "        try:\n",
    "            return int(year.split('–')[0]) >= limit\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "#This function removes irregularities in movies year of production\n",
    "def parse_year(year):\n",
    "    try:\n",
    "        return int(year)\n",
    "    except:\n",
    "        return int(year.split('–')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dropping duplicates from the movies data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping duplicates\n",
    "hollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "bollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "nollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "british_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "chinese_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "korean_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "thai_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "k_drama_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "am_shows_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Collating the movies search parameters(title,year,actors,plot,imdbID) into data structures for easy access</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the part of the movies data needed for querying \n",
    "dict_tags_movies = {\"hollywood\":(hollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + hollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") + \", \" + hollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \", \" + hollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") + \":\" + hollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"bollywood\": (bollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + bollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + bollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + bollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + bollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"nollywood\": (nollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + nollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + nollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + nollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + nollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"british movies\": (british_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + british_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + british_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + british_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + british_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"chinese movies\" :(chinese_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + chinese_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + chinese_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + chinese_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + chinese_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"korean movies\": (korean_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + korean_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + korean_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + korean_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + korean_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"thai movies\" : (thai_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + thai_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + thai_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + thai_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + thai_data['imdbID'].astype(np.str_)).values\n",
    "                        }\n",
    "\n",
    "dict_tags_series = {\"tv-show\": (am_shows_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + am_shows_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + am_shows_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + am_shows_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \":\" + am_shows_data['imdbID'].astype(np.str_)).values,\n",
    "                    \"korean drama\": (k_drama_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + k_drama_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + k_drama_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + k_drama_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \":\" + k_drama_data['imdbID'].astype(np.str_)).values\n",
    "                    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filtering and Parsing the movies data by year of release</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hollywood movies produced before 1990\n",
    "hollywood_data = hollywood_data[hollywood_data[\"year\"]>=1990]\n",
    "\n",
    "#removing bollywood movies produced before 1990\n",
    "bollywood_data = bollywood_data[bollywood_data[\"year\"]>=1990]\n",
    "\n",
    "#removing british movies produced before 1990\n",
    "british_data = british_data[british_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing chinese movies produced before 1970\n",
    "chinese_data = chinese_data[chinese_data[\"year\"].apply(lambda x: filter_year(x,1970))]\n",
    "\n",
    "#removing nollywood movies produced before 1990\n",
    "nollywood_data = nollywood_data[nollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing korean movies produced before 1990\n",
    "korean_data = korean_data[korean_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing thai movies produced before 1990\n",
    "thai_data = thai_data[thai_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing hollywood and bollywood movies produced before 1990 AND Filtering invalid years out\n",
    "bollywood_data = bollywood_data[bollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "hollywood_data = hollywood_data[hollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#Parsing the movies data and fixing the irregularities in them\n",
    "british_data['year'] = british_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "chinese_data['year'] = chinese_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "nollywood_data['year'] = nollywood_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "korean_data['year'] = korean_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "thai_data['year'] = thai_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "bollywood_data['year'] = bollywood_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "hollywood_data['year'] = hollywood_data[\"year\"].apply(parse_year).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Collating the movies data into data structures for easy access</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {\n",
    "\t\"hollywood\":hollywood_data,\n",
    "\t\"bollywood\":bollywood_data,\n",
    "\t\"tv-show\": am_shows_data,\n",
    "    \"british movies\":british_data,\n",
    "    \"chinese movies\":chinese_data,\n",
    "    \"korean movies\":korean_data,\n",
    "    \"nollywood\":nollywood_data,\n",
    "    \"thai movies\":thai_data,\n",
    "    \"korean drama\":k_drama_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting input from user</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie name or tag e.g (john wick, vampire diaries, thanos, vibranium wakanda);\n",
      "Rio\n",
      "Movie Type; (hollywood, bollywood, tv-show, british movies, chinese movies, korean movies, nollywood, thai movies, korean drama)\n",
      "hollywood\n",
      "\n",
      "\n",
      "Rio\n",
      "hollywood\n"
     ]
    }
   ],
   "source": [
    "movie_tag = input('Movie name or tag e.g (john wick, vampire diaries, thanos, vibranium wakanda);\\n')\n",
    "movie_type = input(f'Movie Type; ({\", \".join(dict_data.keys())})\\n')\n",
    "print(f\"\\n\\n{movie_tag}\\n{movie_type}\")\n",
    "if movie_type.lower() in [\"tv-show\",\"korean drama\"]:\n",
    "    movie_type_ = \"series\"\n",
    "else:\n",
    "    movie_type_ = 'movie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Performing the movie query</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Successful\n",
      "(['tt1436562', 'Rio', 'http://www.imdb.com/title/tt1436562/', 6.9, 72.0, 63.0, 208829, 5760, '2011', 1, 3, 30, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'Carlos Saldanha', 'Carlos Saldanha (story)- Earl Richey Jones (story)- Todd R. Jones (story)- Don Rhymer (screenplay)- Joshua Sternin (screenplay)- Jennifer Ventimilia (screenplay)- Sam Harper (screenplay)', 'Karen Disher- Jason Fricchione- Sofia Scarpa Saldanha- Leslie Mann', 'Blue Sky Studios', 'USA- Brazil', 'Arabic- English- Portuguese', 'movie', 'When Blu- a domesticated macaw from small-town Minnesota- meets the fiercely independent Jewel- he takes off on an adventure to Rio de Janeiro with the bird of his dreams.', '$143-619-809', 'G', 'Animation- Adventure- Comedy- Crime- Family- Musical'], 'API Search', None)\n"
     ]
    }
   ],
   "source": [
    "standard_query_data = get_name_movie(movie_tag,dict_tags_movies[movie_type.lower()] if movie_type_ == \"movie\" else dict_tags_series[movie_type.lower()] ,movie_type_)\n",
    "if standard_query_data[0]:\n",
    "    print('Query Successful', standard_query_data, sep=\"\\n\")\n",
    "    queried_movie_type = movie_type.lower()\n",
    "    standard_query_data = standard_query_data[0]\n",
    "else:\n",
    "    print('Query Error', standard_query_data, sep=\"\\n\")\n",
    "    queried_movie_type = None\n",
    "    standard_query_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Processing for machine learning algorithm application</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining Processing Function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts the value of a special nomination from the given string x by using regex\n",
    "def extract_nom_val(x,nom):\n",
    "    try:\n",
    "        res = re.findall(fr'(\\d+?):{nom}', x, re.IGNORECASE)\n",
    "        if res:\n",
    "            return int(res[0]) \n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Processing line of codes </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the needed movie data from the compiled movies data\n",
    "standard_train_data = dict_data[queried_movie_type.lower()]\n",
    "#Getting train_data, a copied version of standard_train_data\n",
    "train_data = standard_train_data.copy()\n",
    "\n",
    "#SUB-categorizing the queried movie type into series or movie\n",
    "if queried_movie_type.lower() in [\"tv-show\",\"korean drama\"]:\n",
    "    queried_movie_type = \"series\"\n",
    "else:\n",
    "    queried_movie_type = 'movie'\n",
    "\n",
    "#Converting the year of release value for the queried movie data into integer(MOVIES Only)\n",
    "if queried_movie_type == 'movie':\n",
    "    try:\n",
    "        standard_query_data[8] = int(standard_query_data[8].split('–')[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#Removing the queried movie data from the train data(IF EXIST)\n",
    "train_data = train_data[train_data['imdbID'] != standard_query_data[0]]\n",
    "\n",
    "#Appending the queried movie data to the train_data for combined data processing, this forms a new data called train_data_with_query\n",
    "train_data_with_query = train_data.append(pd.Series(index=train_data.columns, data=standard_query_data),ignore_index=True)\n",
    "\n",
    "#Dropping the box office attribute from train_data_with_query(MOVIES only)\n",
    "if queried_movie_type != \"series\":\n",
    "    train_data_with_query.drop('BoxOffice',axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "#Treating Missing Values in train_data_with_query\n",
    "\n",
    "#-------Columns or Attributes that will have their missing values replaced with Unknown\n",
    "column_unknown = ['directors','writers', 'actors', 'production', 'country', 'language','Plot','Rated','Type','Genre']\n",
    "for c in column_unknown:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna('Unknown',inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#-------Columns or Attributes that will have their missing values replaced with their respective medians\n",
    "if queried_movie_type == 'movie':\n",
    "    column_median = ['imdbRating', 'rottenTomatoRating','metacriticRating','duration','year']\n",
    "else:\n",
    "    column_median = ['imdbRating','duration', 'totalSeasons']\n",
    "for c in column_median:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(train_data_with_query[c].median(),inplace=True)\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "        \n",
    "#-------Columns or Attributes that will have their missing values replaced with zero(0)        \n",
    "if queried_movie_type == 'movie':\n",
    "    column_zero = ['oscarNominations',\n",
    "           'noOfAwards', 'noOfNominations','imdbVotes']\n",
    "else:\n",
    "    column_zero = ['noOfNominations','imdbVotes','noOfAwards']\n",
    "for c in column_zero:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(0,inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#-------Columns or Attributes that will have their missing values replaced with their respective mode\n",
    "if queried_movie_type == 'movie':\n",
    "    column_mode = []\n",
    "else:\n",
    "    column_mode = ['year']\n",
    "for c in column_mode:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(train_data_with_query[c].mode()[0],inplace=True)\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "\n",
    "        \n",
    "#Extracting the Special Award counts from the movies data(SERIES ONLY)\n",
    "if queried_movie_type.lower() == 'series':\n",
    "    list_special_awards = ['Golden Globe', 'Primetime Emmy']\n",
    "    for spec_nom in list_special_awards:\n",
    "        train_data_with_query[spec_nom] = train_data_with_query['specialNominations'].apply(lambda x: extract_nom_val(x,spec_nom))\n",
    "        column_zero.append(spec_nom)\n",
    "        train_data_with_query[spec_nom].fillna(0,inplace=True)\n",
    "\n",
    "#Parsing the year column of the movies data(SERIES ONLY)\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['year'] = train_data_with_query['year'].apply(lambda x: int(x.split('–')[0]))\n",
    "    column_zero.append('year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compiling labels and id of the columns in train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_init = dict((j,i) for i,j in enumerate(train_data_with_query.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Converting the imdbRating attribute of the train_data_with_query into float data type </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_query.iloc[-1,3] = np.float64(train_data_with_query.iloc[-1,3])\n",
    "train_data_with_query['imdbRating']*=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>getting the queried movie data back from the train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_query_data = train_data_with_query.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining a stop words removal algorithm</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'ourselves', 'hers', 'between', 'yourself', ',', '.', ':', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}\n",
    "def remove_stop_words(x):\n",
    "    return not x in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting some data from the queried movie data, these colleceted data are later used for combined processing of the whole train data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_set = list(i.strip() for i in standard_query_data[dict_cols_init['actors']].split('-'))\n",
    "language_set = list(i.strip() for i in standard_query_data[dict_cols_init['language']].split('-'))\n",
    "genre_set = list(i.strip() for i in standard_query_data[dict_cols_init['Genre']].split('-'))\n",
    "country_set = list(i.strip() for i in standard_query_data[dict_cols_init['country']].split('-'))\n",
    "plot_set = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in standard_query_data[dict_cols_init['Plot']].split())))\n",
    "title_set = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in standard_query_data[dict_cols_init['title']].split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining some processing functions </h4>\n",
    "<h4>These functions returns the length of the intersection of two sets of data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closeness_list(x, to_compare):\n",
    "    a = (len(set(to_compare).intersection(set(x)))/len(to_compare))*(100-len(to_compare))\n",
    "    b = 0\n",
    "    for id_, i in enumerate(x):\n",
    "        try:\n",
    "            if to_compare[id_] == i:\n",
    "                b += 1\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    return a + b\n",
    "\n",
    "def get_plot_match(x):\n",
    "    plot_list = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in x.split())))\n",
    "    a = (len(set(plot_set).intersection(set(plot_list)))/len(plot_set))*100\n",
    "    return a\n",
    "\n",
    "def get_title_match(x):\n",
    "    title_list = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in x.split())))\n",
    "    a = (len(set(title_set).intersection(set(title_list)))/len(title_set))*100\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Performing similarities matching between some attributes of the standard_query_data and the train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actors'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['actors']],x))\n",
    "else:\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actors'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), actors_set))\n",
    "dict_cols_init['actor_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('actor_fuzz')\n",
    "train_data_with_query['language_fuzz'] = train_data_with_query['language'].apply(lambda x:get_closeness_list(list(i.strip() for i in x.split('-')), language_set))\n",
    "dict_cols_init['language_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('language_fuzz')\n",
    "train_data_with_query['rated_fuzz'] = train_data_with_query['Rated'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Rated']],x))\n",
    "dict_cols_init['rated_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('rated_fuzz')\n",
    "train_data_with_query['type_fuzz'] = train_data_with_query['Type'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Type']],x))\n",
    "dict_cols_init['type_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('type_fuzz')\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['Plot'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Plot']],x))\n",
    "else:\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['Plot'].apply(get_plot_match)\n",
    "\n",
    "dict_cols_init['plot_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('plot_fuzz')\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['Genre'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Genre']],x))\n",
    "else:\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['Genre'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), genre_set))\n",
    "dict_cols_init['genre_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('genre_fuzz')\n",
    "# train_data_with_query['country_fuzz'] = train_data_with_query['country'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['country']],x))\n",
    "train_data_with_query['country_fuzz'] = train_data_with_query['country'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), country_set))\n",
    "dict_cols_init['country_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('country_fuzz')\n",
    "# train_data_with_query['title_fuzz'] = train_data_with_query['title'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['title']],x))\n",
    "train_data_with_query['title_fuzz'] = train_data_with_query['title'].apply(get_title_match)\n",
    "dict_cols_init['title_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('title_fuzz')\n",
    "\n",
    "def scale_data(x, col):\n",
    "    return ((x/train_data_with_query[col].max()) * 100)\n",
    "\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['plot_fuzz'].apply(lambda x: 0 if (x <70) else x)\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['genre_fuzz'].apply(lambda x: 0 if (x <70) else x)\n",
    "    train_data_with_query['rated_fuzz'] = train_data_with_query['rated_fuzz'].apply(lambda x: 0 if (x <100) else x)\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actor_fuzz'].apply(lambda x: 0 if (x <80) else x)\n",
    "    train_data_with_query['title_fuzz'] = train_data_with_query['title_fuzz'].apply(lambda x: 0 if (x <80) else x)\n",
    "    train_data_with_query['noOfAwards'] =  train_data_with_query['noOfAwards'].apply(lambda x: scale_data(x, 'noOfAwards'))\n",
    "    train_data_with_query['noOfNominations'] =  train_data_with_query['noOfAwards'].apply(lambda x: scale_data(x, 'noOfNominations'))\n",
    "    train_data_with_query['imdbVotes'] =  train_data_with_query['imdbVotes'].apply(lambda x: scale_data(x, 'imdbVotes'))\n",
    "    # train_data_with_query['Primetime Emmy'] =  train_data_with_query['Primetime Emmy'].apply(lambda x: scale_data(x, 'Primetime Emmy'))\n",
    "    # train_data_with_query['Golden Globe'] =  train_data_with_query['Primetime Emmy'].apply(lambda x: scale_data(x, 'Golden Globe'))\n",
    "else:\n",
    "    train_data_with_query['title_fuzz'] = train_data_with_query['title_fuzz'].apply(lambda x: 0 if (x <80) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filtering and Parsing the Genres attributes of train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_genres = ['Action',\n",
    "       'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Family', 'Fantasy', 'FilmNoir', 'GameShow',\n",
    "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'RealityTV',\n",
    "       'Romance', 'SciFi', 'Short', 'Sport', 'TalkShow', 'Thriller', 'War',\n",
    "       'Western']\n",
    "\n",
    "def parse_genre(x):\n",
    "    try:\n",
    "        if int(x) in [0,1]:\n",
    "            return int[x]\n",
    "        else:\n",
    "            return 0;\n",
    "    except:\n",
    "        return 0\n",
    "for col in column_genres:\n",
    "    train_data_with_query[col] = train_data_with_query[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature Scaling</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>MinMax Scaler is used for movies while Standard Scaler is used for series</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'movie':\n",
    "    scaler = MinMaxScaler()\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "to_be_standardized_features = column_median+column_zero\n",
    "to_be_standardized_data = train_data_with_query[to_be_standardized_features]\n",
    "\n",
    "train_data_with_query_standardized = scaler.fit_transform(to_be_standardized_data)\n",
    "for id_, c in enumerate(to_be_standardized_features):\n",
    "    train_data_with_query[c] = train_data_with_query_standardized[:,id_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compiling labels and id of the columns in train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_final = dict((j,i) for i,j in enumerate(train_data_with_query.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating an algorithm template</h4>\n",
    "<h4>This template specifies the attributes of the movies data on which the algorithm will be applied</h4>\n",
    "<h4>This attributes are specified with their respective index no</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'movie':\n",
    "    distance_template = [\n",
    "        [1, [50,52,53,54,55,3,4,5,6,7,8,10,11,51], 'e','d1',1]\n",
    "    ]\n",
    "else:\n",
    "    distance_template = [\n",
    "        [1, [4,54,55,56], 'e', 'd1', 1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting the data needed to be passed to the fitting function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2d = train_data_with_query.iloc[:-1,:].values\n",
    "labels = train_data_with_query.columns\n",
    "train_data_movie_titles_1d = train_data_with_query.iloc[:-1,:]['title'].values\n",
    "query_data_1d = train_data_with_query.iloc[-1,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Application of Algorithm(Calling the fitting function)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = model_knn(-1, *[train_data_2d, query_data_1d,train_data_movie_titles_1d,distance_template, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Displaying the fitting results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried Movie; Rio\n",
      "Closest Match; Rio, 2011\n",
      "Recommended Movies;;;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rio 2, 2014, tt2357291</td>\n",
       "      <td>[(1.2829200413861803, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ice Age: Dawn of the Dinosaurs, 2009, tt1080016</td>\n",
       "      <td>[(1.5348904294720647, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Princess and the Frog, 2009, tt0780521</td>\n",
       "      <td>[(1.5512377102535446, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Madagascar, 2005, tt0351283</td>\n",
       "      <td>[(1.5595815072365575, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Winnie the Pooh, 2011, tt1449283</td>\n",
       "      <td>[(1.5604986698956342, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Polar Express, 2004, tt0338348</td>\n",
       "      <td>[(1.5654753808043533, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meet the Robinsons, 2007, tt0396555</td>\n",
       "      <td>[(1.5750173181502474, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Book of Life, 2014, tt2262227</td>\n",
       "      <td>[(1.5842962700584073, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scooby-Doo! Music of the Vampire, 2012, tt2162709</td>\n",
       "      <td>[(1.590023677889578, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Toy Story 2, 1999, tt0120363</td>\n",
       "      <td>[(1.6033971713758477, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cars 2, 2011, tt1216475</td>\n",
       "      <td>[(1.6057362707893341, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Piglet's Big Movie, 2003, tt0323642</td>\n",
       "      <td>[(1.608293027896792, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Secret Life of Pets, 2016, tt2709768</td>\n",
       "      <td>[(1.6115215124176412, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Monsters University, 2013, tt1453405</td>\n",
       "      <td>[(1.611792413340153, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Horton Hears a Who!, 2008, tt0451079</td>\n",
       "      <td>[(1.6124191396401932, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jonah: A VeggieTales Movie, 2002, tt0298388</td>\n",
       "      <td>[(1.6131940282239878, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Pirates! Band of Misfits, 2012, tt1430626</td>\n",
       "      <td>[(1.6136551944778592, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ParaNorman, 2012, tt1623288</td>\n",
       "      <td>[(1.6162261009218284, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ferdinand, 2017, tt3411444</td>\n",
       "      <td>[(1.616570772755969, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Curious George, 2006, tt0381971</td>\n",
       "      <td>[(1.6185300739469914, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cars 3, 2017, tt3606752</td>\n",
       "      <td>[(1.618687040662202, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aladdin, 2019, tt6139732</td>\n",
       "      <td>[(1.6226285199968902, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Gnomeo &amp; Juliet, 2011, tt0377981</td>\n",
       "      <td>[(1.622903415502745, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Tale of Despereaux, 2008, tt0420238</td>\n",
       "      <td>[(1.6236987571757369, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The SpongeBob SquarePants Movie, 2004, tt0345950</td>\n",
       "      <td>[(1.6251865195567246, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Trolls, 2016, tt1679335</td>\n",
       "      <td>[(1.626081980576369, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Muppets Most Wanted, 2014, tt2281587</td>\n",
       "      <td>[(1.6264283782883984, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Despicable Me 3, 2017, tt3469046</td>\n",
       "      <td>[(1.6279081552903354, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tangled, 2010, tt0398286</td>\n",
       "      <td>[(1.6301184310016787, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pooh's Heffalump Movie, 2005, tt0407121</td>\n",
       "      <td>[(1.6302064679856632, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Happy Feet, 2006, tt0366548</td>\n",
       "      <td>[(1.630863651246302, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ralph Breaks the Internet, 2018, tt5848272</td>\n",
       "      <td>[(1.6313741055927249, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Smallfoot, 2018, tt6182908</td>\n",
       "      <td>[(1.632807368314127, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Open Season, 2006, tt0400717</td>\n",
       "      <td>[(1.638605722619232, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Frozen II, 2019, tt4520988</td>\n",
       "      <td>[(1.6407969329913814, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Madagascar 3: Europe's Most Wanted, 2012, tt12...</td>\n",
       "      <td>[(1.6413147066750202, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Croods, 2013, tt0481499</td>\n",
       "      <td>[(1.6434395702626916, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cloudy With a Chance of Meatballs 2, 2013, tt1...</td>\n",
       "      <td>[(1.6434616596472522, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mickey- Donald- Goofy: The Three Musketeers, 2...</td>\n",
       "      <td>[(1.6440583481237803, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Teacher's Pet, 2004, tt0350194</td>\n",
       "      <td>[(1.6441629002902531, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Willoughbys, 2020, tt5206260</td>\n",
       "      <td>[(1.6442645136317413, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>George of the Jungle, 1997, tt0119190</td>\n",
       "      <td>[(1.6442770677134324, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tangled Ever After, 2012, tt2112281</td>\n",
       "      <td>[(1.644460868753826, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The LEGO Movie 2: The Second Part, 2019, tt351...</td>\n",
       "      <td>[(1.6444778967986766, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Turbo, 2013, tt1860353</td>\n",
       "      <td>[(1.645038761744723, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Brave, 2012, tt1217209</td>\n",
       "      <td>[(1.6451786645800848, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Smurfs: The Legend of Smurfy Hollow, 2013,...</td>\n",
       "      <td>[(1.6454287381117447, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Madagascar: Escape 2 Africa, 2008, tt0479952</td>\n",
       "      <td>[(1.6454668824553833, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rise of the Guardians, 2012, tt1446192</td>\n",
       "      <td>[(1.646182533871459, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Despicable Me 2, 2013, tt1690953</td>\n",
       "      <td>[(1.6461935684285713, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               imdbID  \\\n",
       "0                              Rio 2, 2014, tt2357291   \n",
       "1     Ice Age: Dawn of the Dinosaurs, 2009, tt1080016   \n",
       "2          The Princess and the Frog, 2009, tt0780521   \n",
       "3                         Madagascar, 2005, tt0351283   \n",
       "4                    Winnie the Pooh, 2011, tt1449283   \n",
       "5                  The Polar Express, 2004, tt0338348   \n",
       "6                 Meet the Robinsons, 2007, tt0396555   \n",
       "7                   The Book of Life, 2014, tt2262227   \n",
       "8   Scooby-Doo! Music of the Vampire, 2012, tt2162709   \n",
       "9                        Toy Story 2, 1999, tt0120363   \n",
       "10                            Cars 2, 2011, tt1216475   \n",
       "11                Piglet's Big Movie, 2003, tt0323642   \n",
       "12           The Secret Life of Pets, 2016, tt2709768   \n",
       "13               Monsters University, 2013, tt1453405   \n",
       "14               Horton Hears a Who!, 2008, tt0451079   \n",
       "15        Jonah: A VeggieTales Movie, 2002, tt0298388   \n",
       "16      The Pirates! Band of Misfits, 2012, tt1430626   \n",
       "17                        ParaNorman, 2012, tt1623288   \n",
       "18                         Ferdinand, 2017, tt3411444   \n",
       "19                    Curious George, 2006, tt0381971   \n",
       "20                            Cars 3, 2017, tt3606752   \n",
       "21                           Aladdin, 2019, tt6139732   \n",
       "22                   Gnomeo & Juliet, 2011, tt0377981   \n",
       "23            The Tale of Despereaux, 2008, tt0420238   \n",
       "24   The SpongeBob SquarePants Movie, 2004, tt0345950   \n",
       "25                            Trolls, 2016, tt1679335   \n",
       "26               Muppets Most Wanted, 2014, tt2281587   \n",
       "27                   Despicable Me 3, 2017, tt3469046   \n",
       "28                           Tangled, 2010, tt0398286   \n",
       "29            Pooh's Heffalump Movie, 2005, tt0407121   \n",
       "30                        Happy Feet, 2006, tt0366548   \n",
       "31         Ralph Breaks the Internet, 2018, tt5848272   \n",
       "32                         Smallfoot, 2018, tt6182908   \n",
       "33                       Open Season, 2006, tt0400717   \n",
       "34                         Frozen II, 2019, tt4520988   \n",
       "35  Madagascar 3: Europe's Most Wanted, 2012, tt12...   \n",
       "36                        The Croods, 2013, tt0481499   \n",
       "37  Cloudy With a Chance of Meatballs 2, 2013, tt1...   \n",
       "38  Mickey- Donald- Goofy: The Three Musketeers, 2...   \n",
       "39                     Teacher's Pet, 2004, tt0350194   \n",
       "40                   The Willoughbys, 2020, tt5206260   \n",
       "41              George of the Jungle, 1997, tt0119190   \n",
       "42                Tangled Ever After, 2012, tt2112281   \n",
       "43  The LEGO Movie 2: The Second Part, 2019, tt351...   \n",
       "44                             Turbo, 2013, tt1860353   \n",
       "45                             Brave, 2012, tt1217209   \n",
       "46  The Smurfs: The Legend of Smurfy Hollow, 2013,...   \n",
       "47       Madagascar: Escape 2 Africa, 2008, tt0479952   \n",
       "48             Rise of the Guardians, 2012, tt1446192   \n",
       "49                   Despicable Me 2, 2013, tt1690953   \n",
       "\n",
       "             Similarity Score  \n",
       "0   [(1.2829200413861803, 1)]  \n",
       "1   [(1.5348904294720647, 1)]  \n",
       "2   [(1.5512377102535446, 1)]  \n",
       "3   [(1.5595815072365575, 1)]  \n",
       "4   [(1.5604986698956342, 1)]  \n",
       "5   [(1.5654753808043533, 1)]  \n",
       "6   [(1.5750173181502474, 1)]  \n",
       "7   [(1.5842962700584073, 1)]  \n",
       "8    [(1.590023677889578, 1)]  \n",
       "9   [(1.6033971713758477, 1)]  \n",
       "10  [(1.6057362707893341, 1)]  \n",
       "11   [(1.608293027896792, 1)]  \n",
       "12  [(1.6115215124176412, 1)]  \n",
       "13   [(1.611792413340153, 1)]  \n",
       "14  [(1.6124191396401932, 1)]  \n",
       "15  [(1.6131940282239878, 1)]  \n",
       "16  [(1.6136551944778592, 1)]  \n",
       "17  [(1.6162261009218284, 1)]  \n",
       "18   [(1.616570772755969, 1)]  \n",
       "19  [(1.6185300739469914, 1)]  \n",
       "20   [(1.618687040662202, 1)]  \n",
       "21  [(1.6226285199968902, 1)]  \n",
       "22   [(1.622903415502745, 1)]  \n",
       "23  [(1.6236987571757369, 1)]  \n",
       "24  [(1.6251865195567246, 1)]  \n",
       "25   [(1.626081980576369, 1)]  \n",
       "26  [(1.6264283782883984, 1)]  \n",
       "27  [(1.6279081552903354, 1)]  \n",
       "28  [(1.6301184310016787, 1)]  \n",
       "29  [(1.6302064679856632, 1)]  \n",
       "30   [(1.630863651246302, 1)]  \n",
       "31  [(1.6313741055927249, 1)]  \n",
       "32   [(1.632807368314127, 1)]  \n",
       "33   [(1.638605722619232, 1)]  \n",
       "34  [(1.6407969329913814, 1)]  \n",
       "35  [(1.6413147066750202, 1)]  \n",
       "36  [(1.6434395702626916, 1)]  \n",
       "37  [(1.6434616596472522, 1)]  \n",
       "38  [(1.6440583481237803, 1)]  \n",
       "39  [(1.6441629002902531, 1)]  \n",
       "40  [(1.6442645136317413, 1)]  \n",
       "41  [(1.6442770677134324, 1)]  \n",
       "42   [(1.644460868753826, 1)]  \n",
       "43  [(1.6444778967986766, 1)]  \n",
       "44   [(1.645038761744723, 1)]  \n",
       "45  [(1.6451786645800848, 1)]  \n",
       "46  [(1.6454287381117447, 1)]  \n",
       "47  [(1.6454668824553833, 1)]  \n",
       "48   [(1.646182533871459, 1)]  \n",
       "49  [(1.6461935684285713, 1)]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Queried Movie; {movie_tag}')\n",
    "print(f'Closest Match; {query_data_1d[1]}, {standard_query_data[8]}')\n",
    "print(f'Recommended Movies;;;')\n",
    "to_extract = standard_train_data.set_index('imdbID').loc[reply[0]['imdbID'],:]\n",
    "pd.concat([reply[0]['imdbID'].apply(lambda x: f'{to_extract.loc[x,\"title\"]}, {to_extract.loc[x,\"year\"]}, {x}'), pd.Series(reply[1], name='Similarity Score')], axis=1).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
