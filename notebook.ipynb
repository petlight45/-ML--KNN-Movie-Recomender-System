{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-Nearsest Neighbour(KNN) Based Movie Recommender Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing the needed libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, seaborn as sns, matplotlib.pyplot as plt,numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler,QuantileTransformer\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining the movie querier function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_movie(queried_movie_name, train_movies_1d, movie_type):\n",
    "    query_method = None\n",
    "    \n",
    "    #This function compiles the queried movie data into the format needed(TV-SHOW ONLY)\n",
    "    def compile_meta_show(imdbID=np.nan, title=np.nan, url=np.nan, imdbRating=np.nan, imdbVotes=np.nan, duration=np.nan,\n",
    "                          year=np.nan, noOfAwards=np.nan, noOfNominations=np.nan, Action=0, Adult=0, Adventure=0,\n",
    "                          Animation=0, Biography=0, Comedy=0, Crime=0, Documentary=0, Drama=0, Family=0, Fantasy=0,\n",
    "                          FilmNoir=0, GameShow=0, History=0, Horror=0, Music=0, Musical=0, Mystery=0, News=0,\n",
    "                          RealityTV=0, Romance=0, SciFi=0, Short=0, Sport=0, TalkShow=0, Thriller=0, War=0, Western=0,\n",
    "                          directors=np.nan, writers=np.nan, actors=np.nan, country=np.nan, language=np.nan, Type=np.nan,\n",
    "                          Plot=np.nan, Rated=np.nan, Genre=np.nan, totalSeasons=np.nan, specialNominations=np.nan):\n",
    "        url = f'http://www.imdb.com/title/{imdbID}/'\n",
    "        return [imdbID, title, url, imdbRating, imdbVotes, duration, year, specialNominations, noOfAwards,\n",
    "                noOfNominations, Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama,\n",
    "                Family, Fantasy, FilmNoir, GameShow, History, Horror, Music, Musical, Mystery, News, RealityTV, Romance,\n",
    "                SciFi, Short, Sport, TalkShow, Thriller, War, Western, directors, writers, actors, country, language,\n",
    "                Type, Plot, Rated, Genre, totalSeasons]\n",
    "    \n",
    "    #This function compiles the queried movie data into the format needed(MOVIES ONLY)\n",
    "    def compile_meta(imdbID=np.nan, title=np.nan, url=np.nan, imdbRating=np.nan,\n",
    "                     rottenTomatoRating=np.nan, metacriticRating=np.nan,\n",
    "                     imdbVotes=np.nan, duration=np.nan, year=np.nan,\n",
    "                     oscarNominations=np.nan, noOfAwards=np.nan, noOfNominations=np.nan, Action=0, Adult=0, Adventure=0,\n",
    "                     Animation=0, Biography=0, Comedy=0, Crime=0, Documentary=0, Drama=0, Family=0, Fantasy=0,\n",
    "                     FilmNoir=0, GameShow=0, History=0, Horror=0, Music=0, Musical=0, Mystery=0, News=0,\n",
    "                     RealityTV=0, Romance=0, SciFi=0, Short=0, Sport=0, TalkShow=0, Thriller=0, War=0,\n",
    "                     Western=0, directors=np.nan, writers=np.nan, actors=np.nan, production=np.nan,\n",
    "                     country=np.nan, language=np.nan, Type=np.nan, Plot=np.nan, BoxOffice=np.nan, Rated=np.nan,\n",
    "                     Genre=np.nan):\n",
    "        url = f'http://www.imdb.com/title/{imdbID}/'\n",
    "        return [imdbID, title, url, imdbRating, rottenTomatoRating, metacriticRating,\n",
    "                imdbVotes, duration, year, oscarNominations, noOfAwards, noOfNominations,\n",
    "                Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary,\n",
    "                Drama, Family, Fantasy, FilmNoir, GameShow, History, Horror, Music, Musical,\n",
    "                Mystery, News, RealityTV, Romance, SciFi, Short, Sport, TalkShow, Thriller,\n",
    "                War, Western, directors, writers, actors, production, country, language,\n",
    "                Type, Plot, BoxOffice, Rated, Genre\n",
    "                ]\n",
    "    #This function gets the meta information of the queried movie by using its IMDB ID\n",
    "    def get_meta(movie_id, type_):\n",
    "        url = \"https://movie-database-imdb-alternative.p.rapidapi.com/\"\n",
    "        headers = {\n",
    "            'x-rapidapi-host': \"movie-database-imdb-alternative.p.rapidapi.com\",\n",
    "            'x-rapidapi-key': \"ce15ebaf8dmshfb3801d1cfa22dcp1f4c05jsn1dad2b361974\"\n",
    "        }\n",
    "        querystring = {\"i\": f\"{movie_id}\", \"r\": \"json\", 'type': type_}\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "        return (response.json())\n",
    "\n",
    "    #This function gets the IMDB ID of a queried movie name\n",
    "    def get_id(m_name, type_):\n",
    "        url = \"https://movie-database-imdb-alternative.p.rapidapi.com/\"\n",
    "        headers = {\n",
    "            'x-rapidapi-host': \"movie-database-imdb-alternative.p.rapidapi.com\",\n",
    "            'x-rapidapi-key': \"ce15ebaf8dmshfb3801d1cfa22dcp1f4c05jsn1dad2b361974\"\n",
    "        }\n",
    "        querystring = {\"page\": \"1\", \"r\": \"json\", \"s\": f\"{m_name}\", 'type': type_}\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "        return (response.json()['Search'][0]['imdbID'])\n",
    "\n",
    "    try:\n",
    "        m_id = get_id(queried_movie_name, movie_type)\n",
    "        query_method = 'API Search'\n",
    "    except KeyError as err:\n",
    "        m_id = \\\n",
    "            process.extractOne(queried_movie_name.lower(), train_movies_1d, scorer=fuzz.token_set_ratio)[0].split(\":\")[\n",
    "                -1]\n",
    "        query_method = 'DATA Search'\n",
    "    except ConnectionError as err:\n",
    "        return (None, 'Connection Error')\n",
    "    except Exception as err:\n",
    "        return (None, err)\n",
    "    try:\n",
    "        movie_meta = get_meta(m_id, movie_type)\n",
    "        if movie_type != \"series\":\n",
    "            log_obj = dict()\n",
    "            log_obj['imdbID'] = movie_meta['imdbID']\n",
    "            log_obj['title'] = movie_meta['Title'].replace(',', \"-\")\n",
    "            dict_ratings = {\n",
    "                'Internet Movie Database': {'name': 'imdbRating', 'pattern': r'(.+?)/'},\n",
    "                'Rotten Tomatoes': {'name': 'rottenTomatoRating', 'pattern': r'(.+?)%'},\n",
    "                'Metacritic': {'name': 'metacriticRating', 'pattern': r'(.+?)/'}\n",
    "            }\n",
    "            for i, j in [(i['Source'], i['Value']) for i in movie_meta['Ratings']]:\n",
    "                log_obj[dict_ratings[i]['name']] = float(re.findall(dict_ratings[i]['pattern'], j)[0])\n",
    "            try:\n",
    "                log_obj['imdbVotes'] = int(movie_meta['imdbVotes'].replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                log_obj['duration'] = int(re.findall(r'(\\d+)', movie_meta['Runtime'])[0]) * 60\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['year'] = movie_meta['Year']\n",
    "            nomination_text = movie_meta['Awards']\n",
    "            if 'Oscar' in nomination_text:\n",
    "                log_obj['oscarNominations'] = int(re.findall(r'(\\d+) Oscar', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'nominations' in nomination_text:\n",
    "                log_obj['noOfNominations'] = int(\n",
    "                    re.findall(r'(\\d+) nominations', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'wins' in nomination_text:\n",
    "                log_obj['noOfAwards'] = int(re.findall(r'(\\d+) wins', nomination_text, re.IGNORECASE)[0])\n",
    "            for i in movie_meta['Genre'].split(','):\n",
    "                log_obj[i.replace(' ', '').replace('-', '')] = 1\n",
    "            log_obj['directors'] = movie_meta['Director'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['writers'] = movie_meta['Writer'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['actors'] = movie_meta['Actors'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            try:\n",
    "                log_obj['production'] = movie_meta['Production'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['country'] = movie_meta['Country'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['language'] = movie_meta['Language'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Plot'] = movie_meta['Plot'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Type'] = movie_meta['Type'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            log_obj['Rated'] = movie_meta['Rated'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            try:\n",
    "                log_obj['BoxOffice'] = movie_meta['BoxOffice'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['Genre'] = movie_meta['Genre'].replace(\",\", '-').replace(\"N/A\", '')\n",
    "            if 'N/A' in log_obj.keys():\n",
    "                del log_obj['N/A']\n",
    "            return (compile_meta(**log_obj), query_method, None)\n",
    "        else:\n",
    "            log_obj = dict()\n",
    "            log_obj['imdbID'] = movie_meta['imdbID']\n",
    "            log_obj['title'] = movie_meta['Title'].replace(',', \"-\")\n",
    "            dict_ratings = {\n",
    "                'Internet Movie Database': {'name': 'imdbRating', 'pattern': r'(.+?)/'}\n",
    "            }\n",
    "            for i, j in [(i['Source'], i['Value']) for i in movie_meta['Ratings']]:\n",
    "                try:\n",
    "                    log_obj[dict_ratings[i]['name']] = float(re.findall(dict_ratings[i]['pattern'], j)[0])\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                log_obj['imdbVotes'] = int(movie_meta['imdbVotes'].replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                log_obj['duration'] = int(re.findall(r'(\\d+)', movie_meta['Runtime'])[0]) * 60\n",
    "            except:\n",
    "                pass\n",
    "            log_obj['year'] = movie_meta['Year']\n",
    "            nomination_text = movie_meta['Awards']\n",
    "            log_obj['specialNominations'] = 'None'\n",
    "            log_obj['noOfNominations'] = 0\n",
    "            log_obj['noOfAwards'] = 0\n",
    "            if 'nominated for' in nomination_text.lower():\n",
    "                for (value, nomination) in re.findall(r'(\\d+?)\\s([a-zA-Z\\s]+)', nomination_text, re.IGNORECASE):\n",
    "                    if not ('nomination' in nomination or 'win' in nomination):\n",
    "                        log_obj['specialNominations'] += f'{value}:{nomination};'\n",
    "            if 'nomination' in nomination_text:\n",
    "                log_obj['noOfNominations'] = int(re.findall(r'(\\d+) nomination', nomination_text, re.IGNORECASE)[0])\n",
    "            if 'win' in nomination_text:\n",
    "                log_obj['noOfAwards'] = int(re.findall(r'(\\d+) win', nomination_text, re.IGNORECASE)[0])\n",
    "            for i in movie_meta['Genre'].split(','):\n",
    "                log_obj[i.replace(' ', '').replace('-', '')] = 1\n",
    "            log_obj['directors'] = movie_meta['Director'].replace(\",\", '-')\n",
    "            log_obj['writers'] = movie_meta['Writer'].replace(\",\", '-')\n",
    "            log_obj['actors'] = movie_meta['Actors'].replace(\",\", '-')\n",
    "            log_obj['country'] = movie_meta['Country'].replace(\",\", '-')\n",
    "            log_obj['language'] = movie_meta['Language'].replace(\",\", '-')\n",
    "            log_obj['Plot'] = movie_meta['Plot'].replace(\",\", '-')\n",
    "            log_obj['Type'] = movie_meta['Type'].replace(\",\", '-')\n",
    "            log_obj['Rated'] = movie_meta['Rated'].replace(\",\", '-')\n",
    "            log_obj['Genre'] = movie_meta['Genre'].replace(\",\", '-')\n",
    "            try:\n",
    "                log_obj['totalSeasons'] = int(movie_meta['totalSeasons'])\n",
    "            except:\n",
    "                pass\n",
    "            if 'N/A' in log_obj.keys():\n",
    "                del log_obj['N/A']\n",
    "            return (compile_meta_show(**log_obj), query_method, None)\n",
    "    except ConnectionError as err:\n",
    "        return (None, 'Connection Error')\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "        return (None, 'Unknown error encountered')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining the predicting algorithm</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(one_d_arr_1,one_d_arr_2):\n",
    "\tif (len(one_d_arr_2) != len(one_d_arr_2)):\n",
    "\t\traise Exception('Eucidean Distance Error; the two 1D arrays have mismatched lengths')\n",
    "\treturn np.linalg.norm(one_d_arr_2-one_d_arr_1)\n",
    "\n",
    "\n",
    "def extract_values(one_d_arr, indices):\n",
    "\treturn one_d_arr[indices]\n",
    "\n",
    "def sort_template_by_rank(distance_template):\n",
    "\treturn sorted(distance_template, key=lambda r:r[0])\n",
    "\n",
    "def compute_distances(query_data_1d, train_data_2d, distance_template):\n",
    "\tsorted_distance_template = sort_template_by_rank(distance_template)\n",
    "\tdistances_computed = list()\n",
    "\tpattern_d_ratio = re.compile('d(\\d+)')\n",
    "\tfor id_, data in enumerate(train_data_2d):\n",
    "\t\tdistance_values =list()\n",
    "\t\tfor *_, indices, method, d_ratio,multiplier in sorted_distance_template:\n",
    "\t\t\tvalues_query = extract_values(query_data_1d, indices)\n",
    "\t\t\tvalues_train = extract_values(data, indices)\n",
    "\t\t\tdistance = euclidean_distance(values_query.astype(np.float64),values_train.astype(np.float64))\n",
    "\t\t\tif pattern_d_ratio.findall(d_ratio)[0] == \"1\":\n",
    "\t\t\t\tdistance = distance\n",
    "\t\t\telse:\n",
    "\t\t\t\tdistance = round(distance / int(pattern_d_ratio.findall(d_ratio)[0]))\n",
    "\t\t\tdistance_values.append((distance,multiplier))\n",
    "\t\tdistances_computed.append((id_, distance_values))\n",
    "\treturn distances_computed\n",
    "\n",
    "def sort_distances_computed(distances_computed):\n",
    "\tdef sorter(x):\n",
    "\t\tsorting_list = list()\n",
    "\t\tfor v,m in x[1]:\n",
    "\t\t\tsorting_list.append(v*m)\n",
    "\t\treturn sorting_list\n",
    "\treturn sorted(distances_computed, key=sorter)\n",
    "\n",
    "\n",
    "\n",
    "def extract_n_neighbours_data(extracting_indices_1d, train_data_2d,k):\n",
    "\tif k > len(extracting_indices_1d):\n",
    "\t\traise Exception('K Error; k > avaailable train data')\n",
    "\tif k == -1:\n",
    "\t\treturn train_data_2d[extracting_indices_1d]\n",
    "\telse:\n",
    "\t\treturn train_data_2d[extracting_indices_1d[:k]]\n",
    "\n",
    "def extract_recommended_distances(sorted_distances_computed,k):\n",
    "\tif k > len(sorted_distances_computed):\n",
    "\t\traise Exception('K Error; k > avaailable train data')\n",
    "\tif k == -1:\n",
    "\t\treturn list(j for *_,j in sorted_distances_computed)\n",
    "\telse:\n",
    "\t\treturn list(j for *_,j in sorted_distances_computed[:k])\n",
    "\n",
    "def extract_recommeded_indices(sorted_distances_computed, k):\n",
    "\n",
    "\tif k > len(sorted_distances_computed):\n",
    "\t\traise Exception('K Error; k > available train data')\n",
    "\tif k == -1:\n",
    "\t\treturn list(i for i,*_ in sorted_distances_computed)\n",
    "\telse:\n",
    "\t\treturn list(i for i,*_ in sorted_distances_computed[:k])\n",
    "\n",
    "\n",
    "def compile_final_output(label_data, recommended_data_2d,recommeded_distances,recommeded_names):\n",
    "\tfinal_label = [*label_data,'Movie Title']\n",
    "\tfinal_data = np.hstack((recommended_data_2d,recommeded_names[:,np.newaxis]))\n",
    "\treturn pd.DataFrame(data=final_data, columns=final_label)\n",
    "\n",
    "\n",
    "def model_knn(k_neighbours, train_data_2d, query_data_1d,train_data_movie_titles_1d,distance_template, label_data=None):\n",
    "\tdistances_computed = compute_distances(query_data_1d,train_data_2d,distance_template)\n",
    "\tsorted_distances_computed = sort_distances_computed(distances_computed)\n",
    "\textracting_indices = list(i for i,*_ in sorted_distances_computed)\n",
    "\trecommended_data_2d = extract_n_neighbours_data(extracting_indices, train_data_2d, k_neighbours)\n",
    "\trecommeded_distances = extract_recommended_distances(sorted_distances_computed, k_neighbours)\n",
    "\trecommeded_indices = extract_recommeded_indices(sorted_distances_computed,k_neighbours)\n",
    "\trecommeded_names = train_data_movie_titles_1d[recommeded_indices]\n",
    "\treturn compile_final_output(label_data,recommended_data_2d,recommeded_distances,recommeded_names),recommeded_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading The Movies Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollywood_data = pd.read_csv(r\"data\\hollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "bollywood_data = pd.read_csv(r\"data\\bollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "british_data = pd.read_csv(r\"data\\british.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "chinese_data = pd.read_csv(r\"data\\chinese.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "korean_data = pd.read_csv(r\"data\\korean.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "nollywood_data = pd.read_csv(r\"data\\nollywood.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "thai_data = pd.read_csv(r\"data\\thai.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "am_shows_data = pd.read_csv(r\"data\\america_tv_show.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)\n",
    "k_drama_data = pd.read_csv(r\"data\\korean_drama.csv\",error_bad_lines=False,index_col=False,warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Cleaning and Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dropping duplicates from the movies data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping duplicates\n",
    "hollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "bollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "nollywood_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "british_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "chinese_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "korean_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "thai_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "k_drama_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n",
    "am_shows_data.drop_duplicates(subset=['imdbID'], keep='first', inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Collating the movies search parameters(title,year,actors,plot,imdbID) into data structures for easy access</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the part of the movies data needed for querying \n",
    "dict_tags_movies = {\"hollywood\":(hollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + hollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") + \", \" + hollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \", \" + hollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") + \":\" + hollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"bollywood\": (bollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + bollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + bollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + bollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + bollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"nollywood\": (nollywood_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + nollywood_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + nollywood_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + nollywood_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + nollywood_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"british movies\": (british_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + british_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + british_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + british_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + british_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"chinese movies\" :(chinese_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + chinese_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + chinese_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + chinese_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + chinese_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"korean movies\": (korean_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + korean_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + korean_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + korean_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + korean_data['imdbID'].astype(np.str_)).values,\n",
    "                         \"thai movies\" : (thai_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + thai_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + thai_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + thai_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\":\" + thai_data['imdbID'].astype(np.str_)).values\n",
    "                        }\n",
    "\n",
    "dict_tags_series = {\"tv-show\": (am_shows_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + am_shows_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + am_shows_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + am_shows_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \":\" + am_shows_data['imdbID'].astype(np.str_)).values,\n",
    "                    \"korean drama\": (k_drama_data['title'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\") +\", \" + k_drama_data['year'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + k_drama_data['actors'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+\", \" + k_drama_data['Plot'].astype(np.str_).str.lower().str.replace(\".\", \"\").str.replace(\",\", \"\").str.replace(\"-\", \"\")+ \":\" + k_drama_data['imdbID'].astype(np.str_)).values\n",
    "                    }    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining parsing and filtering functions for year of production of the movies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function filters out movies that are produced before 2005(TV-SHOW Only)\n",
    "def parse_year_show(x):\n",
    "    try:\n",
    "        return int(x.split('–')[0]) >= 2005\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "#This function filters out movies that are produced before a specified year(defaults to 1990)(MOVIES Only)\n",
    "def filter_year(year, limit=1990):\n",
    "    try:\n",
    "        return int(year) >= limit\n",
    "    except:\n",
    "        try:\n",
    "            return int(year.split('–')[0]) >= limit\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "#This function removes irregularities in movies year of production\n",
    "def parse_year(year):\n",
    "    try:\n",
    "        return int(year)\n",
    "    except:\n",
    "        return int(year.split('–')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filtering and Parsing the movies data by year of release</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hollywood movies produced before 1990\n",
    "hollywood_data = hollywood_data[hollywood_data[\"year\"]>=1990]\n",
    "\n",
    "#removing bollywood movies produced before 1990\n",
    "bollywood_data = bollywood_data[bollywood_data[\"year\"]>=1990]\n",
    "\n",
    "#removing british movies produced before 1990\n",
    "british_data = british_data[british_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing chinese movies produced before 1970\n",
    "chinese_data = chinese_data[chinese_data[\"year\"].apply(lambda x: filter_year(x,1970))]\n",
    "\n",
    "#removing nollywood movies produced before 1990\n",
    "nollywood_data = nollywood_data[nollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing korean movies produced before 1990\n",
    "korean_data = korean_data[korean_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing thai movies produced before 1990\n",
    "thai_data = thai_data[thai_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#removing hollywood and bollywood movies produced before 1990 AND Filtering invalid years out\n",
    "bollywood_data = bollywood_data[bollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "hollywood_data = hollywood_data[hollywood_data[\"year\"].apply(lambda x: filter_year(x))]\n",
    "\n",
    "#Parsing the movies data and fixing the irregularities in them\n",
    "british_data['year'] = british_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "chinese_data['year'] = chinese_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "nollywood_data['year'] = nollywood_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "korean_data['year'] = korean_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "thai_data['year'] = thai_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "bollywood_data['year'] = bollywood_data[\"year\"].apply(parse_year).astype(np.int64)\n",
    "hollywood_data['year'] = hollywood_data[\"year\"].apply(parse_year).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Collating the movies data into data structures for easy access</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {\n",
    "\t\"hollywood\":hollywood_data,\n",
    "\t\"bollywood\":bollywood_data,\n",
    "\t\"tv-show\": am_shows_data,\n",
    "    \"british movies\":british_data,\n",
    "    \"chinese movies\":chinese_data,\n",
    "    \"korean movies\":korean_data,\n",
    "    \"nollywood\":nollywood_data,\n",
    "    \"thai movies\":thai_data,\n",
    "    \"korean drama\":k_drama_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting input from user</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie name or tag e.g (john wick, vampire diaries, thanos, vibranium wakanda);\n",
      "john wick\n",
      "Movie Type; (hollywood, bollywood, tv-show, british movies, chinese movies, korean movies, nollywood, thai movies, korean drama)\n",
      "hollywood\n",
      "\n",
      "\n",
      "john wick\n",
      "hollywood\n"
     ]
    }
   ],
   "source": [
    "movie_tag = input('Movie name or tag e.g (john wick, vampire diaries, thanos, vibranium wakanda);\\n')\n",
    "movie_type = input(f'Movie Type; ({\", \".join(dict_data.keys())})\\n')\n",
    "print(f\"\\n\\n{movie_tag}\\n{movie_type}\")\n",
    "if movie_type.lower() in [\"tv-show\",\"korean drama\"]:\n",
    "    movie_type_ = \"series\"\n",
    "else:\n",
    "    movie_type_ = 'movie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Performing the movie query</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Successful\n",
      "(['tt2911666', 'John Wick', 'http://www.imdb.com/title/tt2911666/', 7.4, 86.0, 68.0, 549197, 6060, '2014', nan, 5, 10, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'Chad Stahelski- David Leitch', 'Derek Kolstad', 'Keanu Reeves- Michael Nyqvist- Alfie Allen- Willem Dafoe', '87eleven- Defynite Films- Thunder Road Pictures', 'USA- UK- China', 'English- Russian- Hungarian', 'movie', 'An ex-hit-man comes out of retirement to track down the gangsters that killed his dog and took everything from him.', '$43-037-835', 'R', 'Action- Crime- Thriller'], 'API Search', None)\n"
     ]
    }
   ],
   "source": [
    "standard_query_data = get_name_movie(movie_tag,dict_tags_movies[movie_type.lower()] if movie_type_ == \"movie\" else dict_tags_series[movie_type.lower()] ,movie_type_)\n",
    "if standard_query_data[0]:\n",
    "    print('Query Successful', standard_query_data, sep=\"\\n\")\n",
    "    queried_movie_type = movie_type.lower()\n",
    "    standard_query_data = standard_query_data[0]\n",
    "else:\n",
    "    print('Query Error', standard_query_data, sep=\"\\n\")\n",
    "    queried_movie_type = None\n",
    "    standard_query_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Processing for machine learning algorithm application</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining Processing Function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts the value of a special nomination from the given string x by using regex\n",
    "def extract_nom_val(x,nom):\n",
    "    try:\n",
    "        res = re.findall(fr'(\\d+?):{nom}', x, re.IGNORECASE)\n",
    "        if res:\n",
    "            return int(res[0]) \n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Processing line of codes </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the needed movie data from the compiled movies data\n",
    "standard_train_data = dict_data[queried_movie_type.lower()]\n",
    "#Getting train_data, a copied version of standard_train_data\n",
    "train_data = standard_train_data.copy()\n",
    "\n",
    "#SUB-categorizing the queried movie type into series or movie\n",
    "if queried_movie_type.lower() in [\"tv-show\",\"korean drama\"]:\n",
    "    queried_movie_type = \"series\"\n",
    "else:\n",
    "    queried_movie_type = 'movie'\n",
    "\n",
    "#Converting the year of release value for the queried movie data into integer(MOVIES Only)\n",
    "if queried_movie_type == 'movie':\n",
    "    try:\n",
    "        standard_query_data[8] = int(standard_query_data[8].split('–')[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#Removing the queried movie data from the train data(IF EXIST)\n",
    "train_data = train_data[train_data['imdbID'] != standard_query_data[0]]\n",
    "\n",
    "#Appending the queried movie data to the train_data for combined data processing, this forms a new data called train_data_with_query\n",
    "train_data_with_query = train_data.append(pd.Series(index=train_data.columns, data=standard_query_data),ignore_index=True)\n",
    "\n",
    "#Dropping the box office attribute from train_data_with_query(MOVIES only)\n",
    "if queried_movie_type != \"series\":\n",
    "    train_data_with_query.drop('BoxOffice',axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "#Treating Missing Values in train_data_with_query\n",
    "\n",
    "#-------Columns or Attributes that will have their missing values replaced with Unknown\n",
    "column_unknown = ['directors','writers', 'actors', 'production', 'country', 'language','Plot','Rated','Type','Genre']\n",
    "for c in column_unknown:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna('Unknown',inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#-------Columns or Attributes that will have their missing values replaced with their respective medians\n",
    "if queried_movie_type == 'movie':\n",
    "    column_median = ['imdbRating', 'rottenTomatoRating','metacriticRating','duration','year']\n",
    "else:\n",
    "    column_median = ['imdbRating','duration', 'totalSeasons']\n",
    "for c in column_median:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(train_data_with_query[c].median(),inplace=True)\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "        \n",
    "#-------Columns or Attributes that will have their missing values replaced with zero(0)        \n",
    "if queried_movie_type == 'movie':\n",
    "    column_zero = ['oscarNominations',\n",
    "           'noOfAwards', 'noOfNominations','imdbVotes']\n",
    "else:\n",
    "    column_zero = ['noOfNominations','imdbVotes','noOfAwards']\n",
    "for c in column_zero:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(0,inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#-------Columns or Attributes that will have their missing values replaced with their respective mode\n",
    "if queried_movie_type == 'movie':\n",
    "    column_mode = []\n",
    "else:\n",
    "    column_mode = ['year']\n",
    "for c in column_mode:\n",
    "    try:\n",
    "        train_data_with_query[c].fillna(train_data_with_query[c].mode()[0],inplace=True)\n",
    "    except Exception as err:\n",
    "        raise err\n",
    "\n",
    "        \n",
    "#Extracting the Special Award counts from the movies data(SERIES ONLY)\n",
    "if queried_movie_type.lower() == 'series':\n",
    "    list_special_awards = ['Golden Globe', 'Primetime Emmy']\n",
    "    for spec_nom in list_special_awards:\n",
    "        train_data_with_query[spec_nom] = train_data_with_query['specialNominations'].apply(lambda x: extract_nom_val(x,spec_nom))\n",
    "        column_zero.append(spec_nom)\n",
    "        train_data_with_query[spec_nom].fillna(0,inplace=True)\n",
    "\n",
    "#Parsing the year column of the movies data(SERIES ONLY)\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['year'] = train_data_with_query['year'].apply(lambda x: int(x.split('–')[0]))\n",
    "    column_zero.append('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compiling labels and id of the columns in train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_init = dict((j,i) for i,j in enumerate(train_data_with_query.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Converting the imdbRating attribute of the train_data_with_query into float data type </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_query.iloc[-1,3] = np.float64(train_data_with_query.iloc[-1,3])\n",
    "train_data_with_query['imdbRating']*=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>getting the queried movie data back from the train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_query_data = train_data_with_query.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining a stop words removal algorithm</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'ourselves', 'hers', 'between', 'yourself', ',', '.', ':', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}\n",
    "def remove_stop_words(x):\n",
    "    return not x in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting some data from the queried movie data, these colleceted data are later used for combined processing of the whole train data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_set = list(i.strip() for i in standard_query_data[dict_cols_init['actors']].split('-'))\n",
    "language_set = list(i.strip() for i in standard_query_data[dict_cols_init['language']].split('-'))\n",
    "genre_set = list(i.strip() for i in standard_query_data[dict_cols_init['Genre']].split('-'))\n",
    "country_set = list(i.strip() for i in standard_query_data[dict_cols_init['country']].split('-'))\n",
    "plot_set = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in standard_query_data[dict_cols_init['Plot']].split())))\n",
    "title_set = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in standard_query_data[dict_cols_init['title']].split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining some processing functions </h4>\n",
    "<h4>These functions returns the length of the intersection of two sets of data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closeness_list(x, to_compare):\n",
    "    try:\n",
    "        a = (len(set(to_compare).intersection(set(x)))/len(to_compare))*(100-len(to_compare))\n",
    "        b = 0\n",
    "        for id_, i in enumerate(x):\n",
    "            try:\n",
    "                if to_compare[id_] == i:\n",
    "                    b += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "        return a + b\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_plot_match(x):\n",
    "    try:\n",
    "        plot_list = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in x.split())))\n",
    "        a = (len(set(plot_set).intersection(set(plot_list)))/len(plot_set))*100\n",
    "        return a\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_title_match(x):\n",
    "    try:\n",
    "        title_list = list(filter(remove_stop_words,set(re.sub(r'(^\\W|\\W$)', '', i).lower() for i in x.split())))\n",
    "        a = (len(set(title_set).intersection(set(title_list)))/len(title_set))*100\n",
    "        return a\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Performing similarities matching between some attributes of the standard_query_data and the train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actors'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['actors']],x))\n",
    "else:\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actors'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), actors_set))\n",
    "dict_cols_init['actor_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('actor_fuzz')\n",
    "train_data_with_query['language_fuzz'] = train_data_with_query['language'].apply(lambda x:get_closeness_list(list(i.strip() for i in x.split('-')), language_set))\n",
    "dict_cols_init['language_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('language_fuzz')\n",
    "train_data_with_query['rated_fuzz'] = train_data_with_query['Rated'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Rated']],x))\n",
    "dict_cols_init['rated_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('rated_fuzz')\n",
    "train_data_with_query['type_fuzz'] = train_data_with_query['Type'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Type']],x))\n",
    "dict_cols_init['type_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('type_fuzz')\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['Plot'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Plot']],x))\n",
    "else:\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['Plot'].apply(get_plot_match)\n",
    "\n",
    "dict_cols_init['plot_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('plot_fuzz')\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['Genre'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['Genre']],x))\n",
    "else:\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['Genre'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), genre_set))\n",
    "dict_cols_init['genre_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('genre_fuzz')\n",
    "# train_data_with_query['country_fuzz'] = train_data_with_query['country'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['country']],x))\n",
    "train_data_with_query['country_fuzz'] = train_data_with_query['country'].apply(lambda x: get_closeness_list(list(i.strip() for i in x.split('-')), country_set))\n",
    "dict_cols_init['country_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('country_fuzz')\n",
    "# train_data_with_query['title_fuzz'] = train_data_with_query['title'].apply(lambda x:fuzz.token_sort_ratio(standard_query_data[dict_cols_init['title']],x))\n",
    "train_data_with_query['title_fuzz'] = train_data_with_query['title'].apply(get_title_match)\n",
    "dict_cols_init['title_fuzz'] = len(dict_cols_init.values())\n",
    "column_median.append('title_fuzz')\n",
    "\n",
    "def scale_data(x, col):\n",
    "    return ((x/train_data_with_query[col].max()) * 100)\n",
    "\n",
    "if queried_movie_type == 'series':\n",
    "    train_data_with_query['plot_fuzz'] = train_data_with_query['plot_fuzz'].apply(lambda x: 0 if (x <70) else x)\n",
    "    train_data_with_query['genre_fuzz'] = train_data_with_query['genre_fuzz'].apply(lambda x: 0 if (x <70) else x)\n",
    "    train_data_with_query['rated_fuzz'] = train_data_with_query['rated_fuzz'].apply(lambda x: 0 if (x <100) else x)\n",
    "    train_data_with_query['actor_fuzz'] = train_data_with_query['actor_fuzz'].apply(lambda x: 0 if (x <80) else x)\n",
    "    train_data_with_query['title_fuzz'] = train_data_with_query['title_fuzz'].apply(lambda x: 0 if (x <80) else x)\n",
    "    train_data_with_query['noOfAwards'] =  train_data_with_query['noOfAwards'].apply(lambda x: scale_data(x, 'noOfAwards'))\n",
    "    train_data_with_query['noOfNominations'] =  train_data_with_query['noOfAwards'].apply(lambda x: scale_data(x, 'noOfNominations'))\n",
    "    train_data_with_query['imdbVotes'] =  train_data_with_query['imdbVotes'].apply(lambda x: scale_data(x, 'imdbVotes'))\n",
    "    # train_data_with_query['Primetime Emmy'] =  train_data_with_query['Primetime Emmy'].apply(lambda x: scale_data(x, 'Primetime Emmy'))\n",
    "    # train_data_with_query['Golden Globe'] =  train_data_with_query['Primetime Emmy'].apply(lambda x: scale_data(x, 'Golden Globe'))\n",
    "else:\n",
    "    train_data_with_query['title_fuzz'] = train_data_with_query['title_fuzz'].apply(lambda x: 0 if (x <80) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filtering and Parsing the Genres attributes of train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_genres = ['Action',\n",
    "       'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Family', 'Fantasy', 'FilmNoir', 'GameShow',\n",
    "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'RealityTV',\n",
    "       'Romance', 'SciFi', 'Short', 'Sport', 'TalkShow', 'Thriller', 'War',\n",
    "       'Western']\n",
    "\n",
    "def parse_genre(x):\n",
    "    try:\n",
    "        if int(x) in [0,1]:\n",
    "            return int[x]\n",
    "        else:\n",
    "            return 0;\n",
    "    except:\n",
    "        return 0\n",
    "for col in column_genres:\n",
    "    train_data_with_query[col] = train_data_with_query[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature Scaling</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>MinMax Scaler is used for movies while Standard Scaler is used for series</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'movie':\n",
    "    scaler = MinMaxScaler()\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "to_be_standardized_features = column_median+column_zero\n",
    "to_be_standardized_data = train_data_with_query[to_be_standardized_features]\n",
    "\n",
    "train_data_with_query_standardized = scaler.fit_transform(to_be_standardized_data)\n",
    "for id_, c in enumerate(to_be_standardized_features):\n",
    "    train_data_with_query[c] = train_data_with_query_standardized[:,id_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compiling labels and id of the columns in train_data_with_query</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_final = dict((j,i) for i,j in enumerate(train_data_with_query.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating an algorithm template</h4>\n",
    "<h4>This template specifies the attributes of the movies data on which the algorithm will be applied</h4>\n",
    "<h4>This attributes are specified with their respective index no</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if queried_movie_type == 'movie':\n",
    "    distance_template = [\n",
    "        [1, [50,52,53,54,55,3,4,5,6,7,8,10,11,51], 'e','d1',1]\n",
    "    ]\n",
    "else:\n",
    "    distance_template = [\n",
    "        [1, [4,54,55,56], 'e', 'd1', 1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting the data needed to be passed to the fitting function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2d = train_data_with_query.iloc[:-1,:].values\n",
    "labels = train_data_with_query.columns\n",
    "train_data_movie_titles_1d = train_data_with_query.iloc[:-1,:]['title'].values\n",
    "query_data_1d = train_data_with_query.iloc[-1,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Application of Algorithm(Calling the fitting function)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = model_knn(-1, *[train_data_2d, query_data_1d,train_data_movie_titles_1d,distance_template, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Displaying the fitting results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried Movie; john wick\n",
      "Closest Match; John Wick, 2014\n",
      "Recommended Movies;;;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Wick: Chapter 2, 2017, tt4425200</td>\n",
       "      <td>[(1.3062114955889452, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Wick: Chapter 3 - Parabellum, 2019, tt614...</td>\n",
       "      <td>[(1.3147311323578028, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headhunters, 2011, tt1614989</td>\n",
       "      <td>[(1.4039350196814966, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Equalizer, 2014, tt0455944</td>\n",
       "      <td>[(1.413424788009761, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machete, 2010, tt0985694</td>\n",
       "      <td>[(1.4814297975055375, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Walk Among the Tombstones, 2014, tt0365907</td>\n",
       "      <td>[(1.4875273941273846, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Girl with the Dragon Tattoo, 2009, tt1132620</td>\n",
       "      <td>[(1.4970927728456827, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ronin, 1998, tt0122690</td>\n",
       "      <td>[(1.4972628589606598, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eastern Promises, 2007, tt0765443</td>\n",
       "      <td>[(1.4979008655790387, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RocknRolla, 2008, tt1032755</td>\n",
       "      <td>[(1.5033833611035596, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Girl Who Played with Fire, 2009, tt1216487</td>\n",
       "      <td>[(1.5040788777937175, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Blade Runner 2049, 2017, tt1856101</td>\n",
       "      <td>[(1.5053563979283016, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Drop, 2014, tt1600196</td>\n",
       "      <td>[(1.5068653767953892, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Game Night, 2018, tt2704998</td>\n",
       "      <td>[(1.5098523911797934, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Spy, 2015, tt3079380</td>\n",
       "      <td>[(1.5112217587938956, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Running Scared, 2006, tt0404390</td>\n",
       "      <td>[(1.5124660607548526, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A Scanner Darkly, 2006, tt0405296</td>\n",
       "      <td>[(1.5126543710419966, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atomic Blonde, 2017, tt2406566</td>\n",
       "      <td>[(1.5128027312329269, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Triple 9, 2016, tt1712261</td>\n",
       "      <td>[(1.521117334332153, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Boiler Room, 2000, tt0181984</td>\n",
       "      <td>[(1.5249223378374284, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Spartan, 2004, tt0360009</td>\n",
       "      <td>[(1.5264366546719406, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Transsiberian, 2008, tt0800241</td>\n",
       "      <td>[(1.5273095153555585, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Our Kind of Traitor, 2016, tt1995390</td>\n",
       "      <td>[(1.53180964881671, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Boondock Saints, 1999, tt0144117</td>\n",
       "      <td>[(1.5324992723756132, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Accident Man, 2018, tt6237612</td>\n",
       "      <td>[(1.532524478792192, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Street Kings, 2008, tt0421073</td>\n",
       "      <td>[(1.534858009414596, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Unthinkable, 2010, tt0914863</td>\n",
       "      <td>[(1.5351520621510855, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Snowden, 2016, tt3774114</td>\n",
       "      <td>[(1.5362242836158315, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Predators, 2010, tt1424381</td>\n",
       "      <td>[(1.5369816630313733, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hustlers, 2019, tt5503686</td>\n",
       "      <td>[(1.537493637315018, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cold Pursuit, 2019, tt5719748</td>\n",
       "      <td>[(1.5398466855011994, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Layer Cake, 2004, tt0375912</td>\n",
       "      <td>[(1.5406777354476693, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Hitman's Bodyguard, 2017, tt1959563</td>\n",
       "      <td>[(1.543467986658601, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Money Monster, 2016, tt2241351</td>\n",
       "      <td>[(1.545598695054391, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lord of War, 2005, tt0399295</td>\n",
       "      <td>[(1.5480041410028842, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Good Liar, 2019, tt5563334</td>\n",
       "      <td>[(1.549889020677869, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Defiance, 2008, tt1034303</td>\n",
       "      <td>[(1.550386895396491, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Munich, 2005, tt0408306</td>\n",
       "      <td>[(1.5515752102586127, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Purge: Election Year, 2016, tt4094724</td>\n",
       "      <td>[(1.5519107327784285, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hardcore Henry, 2015, tt3072482</td>\n",
       "      <td>[(1.552802299782734, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Unleashed, 2005, tt0342258</td>\n",
       "      <td>[(1.5530209617086044, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>We Own the Night, 2007, tt0498399</td>\n",
       "      <td>[(1.5580545911705643, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logan, 2017, tt3315342</td>\n",
       "      <td>[(1.558736160574118, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Training Day, 2001, tt0139654</td>\n",
       "      <td>[(1.5625376380831049, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22 July, 2018, tt7280898</td>\n",
       "      <td>[(1.5644771238499002, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Foreigner, 2017, tt1615160</td>\n",
       "      <td>[(1.570572863733087, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>End of Watch, 2012, tt1855199</td>\n",
       "      <td>[(1.571632642657948, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The Nice Guys, 2016, tt3799694</td>\n",
       "      <td>[(1.572967172841163, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Dead Man Down, 2013, tt2101341</td>\n",
       "      <td>[(1.573402475519269, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Red Sparrow, 2018, tt2873282</td>\n",
       "      <td>[(1.576100972911484, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               imdbID  \\\n",
       "0               John Wick: Chapter 2, 2017, tt4425200   \n",
       "1   John Wick: Chapter 3 - Parabellum, 2019, tt614...   \n",
       "2                        Headhunters, 2011, tt1614989   \n",
       "3                      The Equalizer, 2014, tt0455944   \n",
       "4                            Machete, 2010, tt0985694   \n",
       "5        A Walk Among the Tombstones, 2014, tt0365907   \n",
       "6    The Girl with the Dragon Tattoo, 2009, tt1132620   \n",
       "7                              Ronin, 1998, tt0122690   \n",
       "8                   Eastern Promises, 2007, tt0765443   \n",
       "9                         RocknRolla, 2008, tt1032755   \n",
       "10     The Girl Who Played with Fire, 2009, tt1216487   \n",
       "11                 Blade Runner 2049, 2017, tt1856101   \n",
       "12                          The Drop, 2014, tt1600196   \n",
       "13                        Game Night, 2018, tt2704998   \n",
       "14                               Spy, 2015, tt3079380   \n",
       "15                    Running Scared, 2006, tt0404390   \n",
       "16                  A Scanner Darkly, 2006, tt0405296   \n",
       "17                     Atomic Blonde, 2017, tt2406566   \n",
       "18                          Triple 9, 2016, tt1712261   \n",
       "19                       Boiler Room, 2000, tt0181984   \n",
       "20                           Spartan, 2004, tt0360009   \n",
       "21                     Transsiberian, 2008, tt0800241   \n",
       "22               Our Kind of Traitor, 2016, tt1995390   \n",
       "23               The Boondock Saints, 1999, tt0144117   \n",
       "24                      Accident Man, 2018, tt6237612   \n",
       "25                      Street Kings, 2008, tt0421073   \n",
       "26                       Unthinkable, 2010, tt0914863   \n",
       "27                           Snowden, 2016, tt3774114   \n",
       "28                         Predators, 2010, tt1424381   \n",
       "29                          Hustlers, 2019, tt5503686   \n",
       "30                      Cold Pursuit, 2019, tt5719748   \n",
       "31                        Layer Cake, 2004, tt0375912   \n",
       "32            The Hitman's Bodyguard, 2017, tt1959563   \n",
       "33                     Money Monster, 2016, tt2241351   \n",
       "34                       Lord of War, 2005, tt0399295   \n",
       "35                     The Good Liar, 2019, tt5563334   \n",
       "36                          Defiance, 2008, tt1034303   \n",
       "37                            Munich, 2005, tt0408306   \n",
       "38          The Purge: Election Year, 2016, tt4094724   \n",
       "39                    Hardcore Henry, 2015, tt3072482   \n",
       "40                         Unleashed, 2005, tt0342258   \n",
       "41                  We Own the Night, 2007, tt0498399   \n",
       "42                             Logan, 2017, tt3315342   \n",
       "43                      Training Day, 2001, tt0139654   \n",
       "44                           22 July, 2018, tt7280898   \n",
       "45                     The Foreigner, 2017, tt1615160   \n",
       "46                      End of Watch, 2012, tt1855199   \n",
       "47                     The Nice Guys, 2016, tt3799694   \n",
       "48                     Dead Man Down, 2013, tt2101341   \n",
       "49                       Red Sparrow, 2018, tt2873282   \n",
       "\n",
       "             Similarity Score  \n",
       "0   [(1.3062114955889452, 1)]  \n",
       "1   [(1.3147311323578028, 1)]  \n",
       "2   [(1.4039350196814966, 1)]  \n",
       "3    [(1.413424788009761, 1)]  \n",
       "4   [(1.4814297975055375, 1)]  \n",
       "5   [(1.4875273941273846, 1)]  \n",
       "6   [(1.4970927728456827, 1)]  \n",
       "7   [(1.4972628589606598, 1)]  \n",
       "8   [(1.4979008655790387, 1)]  \n",
       "9   [(1.5033833611035596, 1)]  \n",
       "10  [(1.5040788777937175, 1)]  \n",
       "11  [(1.5053563979283016, 1)]  \n",
       "12  [(1.5068653767953892, 1)]  \n",
       "13  [(1.5098523911797934, 1)]  \n",
       "14  [(1.5112217587938956, 1)]  \n",
       "15  [(1.5124660607548526, 1)]  \n",
       "16  [(1.5126543710419966, 1)]  \n",
       "17  [(1.5128027312329269, 1)]  \n",
       "18   [(1.521117334332153, 1)]  \n",
       "19  [(1.5249223378374284, 1)]  \n",
       "20  [(1.5264366546719406, 1)]  \n",
       "21  [(1.5273095153555585, 1)]  \n",
       "22    [(1.53180964881671, 1)]  \n",
       "23  [(1.5324992723756132, 1)]  \n",
       "24   [(1.532524478792192, 1)]  \n",
       "25   [(1.534858009414596, 1)]  \n",
       "26  [(1.5351520621510855, 1)]  \n",
       "27  [(1.5362242836158315, 1)]  \n",
       "28  [(1.5369816630313733, 1)]  \n",
       "29   [(1.537493637315018, 1)]  \n",
       "30  [(1.5398466855011994, 1)]  \n",
       "31  [(1.5406777354476693, 1)]  \n",
       "32   [(1.543467986658601, 1)]  \n",
       "33   [(1.545598695054391, 1)]  \n",
       "34  [(1.5480041410028842, 1)]  \n",
       "35   [(1.549889020677869, 1)]  \n",
       "36   [(1.550386895396491, 1)]  \n",
       "37  [(1.5515752102586127, 1)]  \n",
       "38  [(1.5519107327784285, 1)]  \n",
       "39   [(1.552802299782734, 1)]  \n",
       "40  [(1.5530209617086044, 1)]  \n",
       "41  [(1.5580545911705643, 1)]  \n",
       "42   [(1.558736160574118, 1)]  \n",
       "43  [(1.5625376380831049, 1)]  \n",
       "44  [(1.5644771238499002, 1)]  \n",
       "45   [(1.570572863733087, 1)]  \n",
       "46   [(1.571632642657948, 1)]  \n",
       "47   [(1.572967172841163, 1)]  \n",
       "48   [(1.573402475519269, 1)]  \n",
       "49   [(1.576100972911484, 1)]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Queried Movie; {movie_tag}')\n",
    "print(f'Closest Match; {query_data_1d[1]}, {standard_query_data[8]}')\n",
    "print(f'Recommended Movies;;;')\n",
    "to_extract = standard_train_data.set_index('imdbID').loc[reply[0]['imdbID'],:]\n",
    "pd.concat([reply[0]['imdbID'].apply(lambda x: f'{to_extract.loc[x,\"title\"]}, {to_extract.loc[x,\"year\"]}, {x}'), pd.Series(reply[1], name='Similarity Score')], axis=1).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
